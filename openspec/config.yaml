schema: spec-driven

# Project context
context: |
  Project: local-memory - High-performance local GraphRAG memory system with MCP integration
  
  Description:
    A Rust-based GraphRAG memory system that stores, searches, and retrieves memories
    using a combination of vector embeddings and Knowledge Graph traversal.
    Features hybrid retrieval with SQLite and sqlite-vec.

  Tech Stack:
    - Language: Rust 2024 edition
    - Package Manager: Cargo
    - Build System: cargo build, cargo build --release
    - Testing: cargo test, criterion benchmarks
    - Database: SQLite with sqlite-vec extension
    - LLM Integration: edgequake-llm for entity/relationship extraction

  Key Dependencies:
    - rusqlite: SQLite driver with bundled support
    - sqlite-vec: Vector search extension for SQLite
    - edgequake-llm: Unified LLM provider interface
    - candle-core/nn/transformers: Local embedding model execution
    - tokio: Async runtime
    - uuid: Unique identifiers
    - serde/serde_json: JSON serialization
    - clap: CLI argument parsing

  Embedding Model:
    - Nomic Embed Text v1.5
    - 768-dimensional vectors
    - Local execution via Candle

  Project Structure:
    - src/ - Main source code
      - main.rs - MCP server entry point
      - cli.rs - CLI implementation (lmcli)
      - config.rs - Configuration handling
      - lib.rs - Library root
      - bin/lmcli.rs - CLI binary
      - engine/ - Core processing logic
        - ingestion.rs - GraphRAG ingestion pipeline (Text -> Vector + KG)
        - funnel.rs - Hybrid search coordinator (Vector + Graph)
      - model/ - Embedding model
        - nomic.rs - Nomic model implementation
        - downloader.rs - Model download utility
      - storage/ - Persistence layer
        - sqlite.rs - SQLite storage with sqlite-vec integration
        - mod.rs - Storage module exports
      - mcp/ - MCP protocol implementation
        - tools.rs - MCP tool implementations
    - tests/ - Integration tests
      - edgequake_integration_test.rs - Comprehensive GraphRAG flow tests
    - docs/ - Documentation
      - ARCHITECTURE.md - System architecture
      - MCP_INTEGRATION.md - MCP client integration guide
    - openspec/ - OpenSpec specifications
    - .opencode/ - OpenCode MCP config and skills
    - .gemini/ - Gemini CLI skills and commands

  Retrieval Architecture (Hybrid Funnel):
    - Vector Search: KNN search against document embeddings using sqlite-vec.
    - Graph Expansion: Traversing entities and relationships to find related context.
    - Context Fusion: Merging text chunks and graph triplets for final response.

  MCP/Client Integration:
    Target Agent Environments:
      - OpenCode (primary): MCP server configuration
      - Claude Desktop: MCP stdio integration
      - Gemini CLI: Skills and commands integration

    MCP Tools:
      - memory_insert: Ingest text and extract Knowledge Graph data.
      - memory_search: Hybrid vector and graph search.
      - graph_get_neighborhood: Explore entity connections.

    CLI Tool (lmcli):
      - lmcli stats: Show database statistics and entity counts.
      - lmcli list-entities: List extracted Knowledge Graph entities.
      - lmcli list-relations: List Knowledge Graph relationships.
      - lmcli search <query>: Perform hybrid search.
      - lmcli test: Run diagnostic self-tests.

  Conventions:
    - Use cargo for all build and dependency management
    - Run `cargo build --release` for optimized builds
    - Run `cargo test` for unit and integration tests
    - Model files must be present in models/ directory
    - MCP server communicates via stdio using JSON-RPC 2.0
    - Knowledge Graph extraction requires a configured LLM (e.g., OPENAI_API_KEY)

# Per-artifact rules
rules:
  # General rules for all artifacts
  general:
    - "CRITICAL: All OpenSpec commands MUST be run from project root"
    - All OpenSpec artifacts MUST be located in openspec/ at project root
    - The openspec/ directory is the single canonical location for all specification artifacts
    - Keep specifications in sync with implementation changes
    - All public APIs must have documentation comments

  # Consistency and cleanup workflow
  consistency:
    - Verify that specs and plans in openspec/ are consistent with current implementation
    - Check for outdated or obsolete specifications that no longer match reality
    - Keep openspec/ directory clean, consistent, and up-to-date at all times

  proposal:
    - Always include "Goals" and "Non-goals" sections
    - Consider impact on hybrid search performance and SQLite storage

  spec:
    - Follow OpenSpec structure for all specifications
    - Document Knowledge Graph schema changes and hybrid search logic
    - Keep specs as living documents - update when implementation evolves

  tasks:
    - Task definitions must adhere to OpenSpec task format
    - Run `cargo test` after code changes
    - Run `cargo clippy` to catch issues early
